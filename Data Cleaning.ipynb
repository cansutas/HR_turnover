{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "This notebook will create a single dataframe to use in the rest of the analysis, using the 4 different data sources we have. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "default_path='C:/Users/CAT/OneDrive - Equinor/Projects/Project Strech/Project v.1'\n",
    "os.chdir(default_path)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from functions import fill_month\n",
    "from functions import id_diff\n",
    "from functions import count_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data showing who left the company\n",
    "leav= pd.read_csv(\"data/raw/Leav_18.csv\", sep=';')\n",
    "#main dataframe\n",
    "main= pd.read_csv(\"data/raw/full_data_monthly_18.csv\", sep=';', encoding='latin-1')\n",
    "#additional travel data\n",
    "trv= pd.read_csv('data/raw/travel_costs_18.csv', sep=';', encoding='latin-1')\n",
    "#additional timewriting data\n",
    "absence= pd.read_csv('data/raw/time_absence_18.csv', sep=';', encoding='latin-1')\n",
    "attend= pd.read_csv('data/raw/time_attendance_18.csv', sep=';', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset that has the country-nationality pairs to use as a dictionary later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df with country-nation pairs\n",
    "count_dict= pd.read_csv('data/supporting/country dict.csv',\n",
    "                        header=None,index_col=0,squeeze=True, encoding='latin-1').to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the columns of the datasets to make sure all columns that have the matching data have the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename and clean columns\n",
    "rename_dict= {'Cal. year / month': 'date' , \n",
    "             'Employee Equinor': 'id',\n",
    "             'Employee Equinor.1':'name',\n",
    "             'Length of service':'service_length',\n",
    "             'Age in Years':'age',\n",
    "             'Host Country':'host_country',\n",
    "             'Nationality': 'nation',\n",
    "             'Manager (ref. zansnr':'manager_id',\n",
    "             'Manager (ref. zansnr.1':'manager',\n",
    "             'Chief Position':'is_manager',\n",
    "             'Orgunit BA':'BA',\n",
    "             'Organizational level':'org_level',\n",
    "             'Discipline.1':'discipline_id',\n",
    "             'Discipline':'discipline_id',\n",
    "             'Moves for Permanent employees (from)': 'Leavers', \n",
    "             'Branch of study':'study',\n",
    "             'Process Network':'network', \n",
    "             'Certificate':'certif'\n",
    "             }\n",
    "\n",
    "leav = leav.rename(columns=rename_dict)\n",
    "main=main.rename(columns=rename_dict)\n",
    "attend=attend.rename(columns={'Cal. year / month': 'date' , 'Hours':'attend'})\n",
    "absence=absence.rename(columns={'Cal. year / month': 'date' , 'Hours':'absence'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop some rows that are created during data extraction and create lists of id's that we will use later. Lastly convert the numerical columns to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leav = leav[~leav.isin(['Result', 'Overall Result']).any(axis=1)]\n",
    "main = main[~main.isin(['Result', 'Overall Result']).any(axis=1)]\n",
    "absence = absence[~absence.isin(['Result', 'Overall Result']).any(axis=1)]\n",
    "attend = attend[~attend.isin(['Result', 'Overall Result']).any(axis=1)]\n",
    "trv = trv[~trv.isin(['Result', 'Overall Result']).any(axis=1)]\n",
    "\n",
    "#drop a useless column \n",
    "main.drop(['Unnamed: 16'], axis=1, inplace=True)\n",
    "\n",
    "#create a list of id's that were found in the main dataset \n",
    "id_list= list(main['id'].unique())\n",
    "#create a list of id's that have left the company\n",
    "leaver_list= list(leav['id'].unique())\n",
    "\n",
    "#convert the numerical columns to numerical\n",
    "#replace the , decimal with . and then round \n",
    "absence['absence'] = pd.to_numeric(absence['absence'].astype('str').apply(lambda x: x.replace(',', '.'))).round()\n",
    "attend['attend'] = pd.to_numeric(attend['attend'].astype('str').apply(lambda x: x.replace(',', '.'))).round()\n",
    "trv['travel_avg'] = pd.to_numeric(trv['travel_avg'].astype('str').apply(lambda x: x.replace(',', '.'))).round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge on id and name using outer to see if there are points from the dfs that don't match \n",
    "df=pd.DataFrame.merge(main,leav, on=['id', 'name'], how='outer')\n",
    "df['Leavers']= df['Leavers'].replace(np.nan, 0) #If wasn't in the leavers dataset, then not leaver\n",
    "\n",
    "#keep only the data where id includes the ids from the xtra info\n",
    "df=df[df['id'].isin(id_list)] #this drops all the missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data sets have a date column but they have different structures. On top of that, there are different number of rows for each employee in each data set (see ReadMe). So we'll need to populate all the data sets so that every employee has one row per month in the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete missing month data\n",
    "df = fill_month(df, '2017-12-01', '2018-12-31', 'MS') #data set is from 12.17 to 12.18\n",
    "df.sort_values(by=['id', 'date'], inplace=True) \n",
    "df=df.groupby(['id']).ffill()\n",
    "df=df.bfill()\n",
    "\n",
    "absence= fill_month(absence, '2017-12-01', '2018-12-31', 'MS')\n",
    "attend= fill_month(attend, '2017-12-01', '2018-12-31', 'MS')\n",
    "\n",
    "attend['attend']= attend['attend'].replace(np.nan, 0) #If wasn't in the leavers dataset, then not leaver\n",
    "absence['absence']= absence['absence'].replace(np.nan, 0) #If wasn't in the leavers dataset, then not leaver\n",
    "\n",
    "absence=absence.drop(['name'], axis=1)\n",
    "attend=attend.drop(['name'], axis=1)\n",
    "trv=trv.drop(['name'], axis=1)\n",
    "\n",
    "#same for the time and travel datasets\n",
    "dfs=[df, absence, attend, trv]\n",
    "for dfx in dfs:\n",
    "    dfx['id']=pd.to_numeric(dfx['id'])\n",
    "\n",
    "df1=pd.DataFrame.merge(df,trv, on=['id'], how='outer')\n",
    "\n",
    "#merge multiple datasets\n",
    "dfs=[df1, absence, attend]\n",
    "df_final = reduce(lambda left,right: pd.merge(left,right,on=['id', 'date'], how='outer'), dfs)\n",
    "\n",
    "#choose only the ids that were in the main dataset\n",
    "df=df_final[df_final['id'].isin([int(x) for x in id_list])] \n",
    "\n",
    "df.isnull().sum() #the ids from time\n",
    "#see if everyone has 14 rows\n",
    "df.groupby('id')['id'].count().unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recoding Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#___give numerical values to the band and org level \n",
    "band_dict={'PROF':3,'PRIN PROF':4,'LEAD PROF':5,'ASSOCIATE':2,'OPER & SUPP':1,\n",
    "           'MANAGER':6, 'EXECUTIVE':7, 'SR EXEC':8}\n",
    "\n",
    "org_lev_dict={'Dept level 5':6, 'Sector Level':5, 'Dept level 6':7, 'Business Unit':4,\n",
    "       'Business Cluster':3, 'Business Area':2, 'Corporate':1, 'Dept level 7':8,\n",
    "       'Dept level 8':9}\n",
    "\n",
    "df['Band']= df['Band'].replace(band_dict)\n",
    "df['org_level']= df['org_level'].replace(org_lev_dict)\n",
    "\n",
    "#___fix the categorical variables to binary\n",
    "df['is_manager']= df['is_manager'].replace({'#':0, 'X':1})\n",
    "df['Gender']=df['Gender'].replace(2, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting different conotations for missing value to np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the number of Not assigned\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == object:\n",
    "        count = 0\n",
    "        count = [count + 1 for x in df[col] if x == 'Not assigned']\n",
    "        print(col + ' ' + str(sum(count)))\n",
    "\n",
    "#convert different type of NaN to np.nan\n",
    "df= df.replace('Not assigned',np.nan) \n",
    "df= df.replace('#',np.nan)\n",
    "\n",
    "df.describe()\n",
    "#If wasn't in the dataset, then replace the nan for that month with 0\n",
    "df['attend']= df['attend'].replace(np.nan, 0) \n",
    "df['absence']= df['absence'].replace(np.nan, 0) \n",
    "df['travel_avg']= df['travel_avg'].replace(np.nan, 0) \n",
    "df['service_length']= df['service_length'].replace(np.nan, 0)     \n",
    "\n",
    "#there are employees with different certificate information in different months\n",
    "#replace the \"meaningless\" certificates with more meaningful certificate info if it exists\n",
    "certif_dict = dict.fromkeys(['DD', 'CE', 'DE', 'BD', 'ED', 'BB', 'DG', 'EJ', 'DH', 'BC', 'BA',\n",
    "       'BG', 'BH', 'EE', 'EC', 'CB', 'DF',  'DI', 'CA'], np.nan)\n",
    "certif_dict['99']=np.nan \n",
    "df['certif']= df['certif'].replace(certif_dict)\n",
    "df.sort_values(by=['id', 'date'], inplace=True) \n",
    "df[['id', 'certif']]=df[['id', 'certif']].groupby(['id']).ffill()\n",
    "df[['id','certif']]=df[['id', 'certif']].groupby(['id']).bfill()\n",
    "\n",
    "#convert numeric to numeric\n",
    "cont_var=['service_length', 'manager_id', 'certif'] #numeric variables\n",
    "for x in cont_var:\n",
    "    df[x]=pd.to_numeric(df[x], errors='raise')\n",
    "\n",
    "#dataframe with columns that have missing values\n",
    "miss=df[df.isnull().any(axis=1)]\n",
    "#see if there are employees that have only some months missing within a column\n",
    "miss['Leavers'].sum()/13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill some missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill missing org_level based on the average org_level of the same band\n",
    "miss_ids= list(df['id'][df.isnull().sum(axis=1)>4].unique())\n",
    "df=df[~df['id'].isin(miss_ids)] \n",
    "\n",
    "#Fill missing Bands and org level based on the averages\n",
    "df['org_level'].fillna(df.groupby('Band')['org_level'].transform('mean').round(), inplace=True)\n",
    "#Band: assign average band level aggregataed over org level and age\n",
    "df['Band'].fillna(df.groupby(['org_level', 'Age'])['Band'].transform('mean').round(), inplace=True)\n",
    "df['certif'].fillna(df.groupby(['Band', 'is_manager'])['certif'].transform('median').round(), inplace=True)\n",
    "\n",
    "df.drop(columns='manager', inplace=True)\n",
    "\n",
    "df.sort_values(by=['id', 'date'], inplace=True) \n",
    "df[['id', 'manager_id']]=df[['id', 'manager_id']].groupby(['id']).ffill()\n",
    "df[['id','manager_id']]=df[['id', 'manager_id']].groupby(['id']).bfill()\n",
    "\n",
    "#assing a manager to missing managers based on most common manager within band, ba and org_level combo\n",
    "df['manager_id'].fillna(df.groupby(['Band', 'BA', 'org_level'])['manager_id'].transform('median'), inplace=True)\n",
    "\n",
    "#check the list of employees who still have a missing value\n",
    "miss_ids= list(df['id'][df.isnull().sum(axis=1)>0].unique())\n",
    "df=df[~df['id'].isin(miss_ids)] \n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create historical data for host country and discipline\n",
    "#count number of countries/disciplines each person have changes in the last year\n",
    "df['host_count']=df.groupby('id')['host_country'].transform('nunique')\n",
    "df['network_count']=df.groupby('id')['network'].transform('nunique')\n",
    "\n",
    "#create promotion data\n",
    "df.sort_values(by=['id', 'date'], inplace=True) \n",
    "df['promotion_1'] = df['Band'].diff() #create new variable with the difference of promotion variable latter row-previous row\n",
    "mask = df.id != df.id.shift(1) #create mask where ids are different from row to row (new person) \n",
    "df['promotion_1'][mask] = 0 \n",
    "#copy the data to all rows promotion column for each person\n",
    "df['promotion'] = df.groupby(['id'])['promotion_1'].apply(lambda x: x.cumsum())\n",
    "df.drop(columns=['promotion_1'], inplace=True)\n",
    "#df.isnull().sum()\n",
    "\n",
    "#create a new variable called expat based on the nation and host country information\n",
    "df['nation'].head()\n",
    "df['host_country'].head()\n",
    "#all lower case\n",
    "df.nation = df.nation.astype(str).apply(lambda x: x.lower())\n",
    "df.host_country = df.host_country.astype(str).apply(lambda x: x.lower())\n",
    "count_dict= {k.lower(): v.lower() for k, v in count_dict.items()}\n",
    "\n",
    "df['nation']= df['nation'].replace({'nan':np.nan,'kasachstani':'kazakh',\n",
    "  'columbian':'colombian', 'brithish':'british','white-russian':'belarusian',\n",
    "  'f. trinidad & t':'trinidadian', 'ghanian':'ghanaian', 'neth.antillean':'antillean'})\n",
    "\n",
    "df['host_country']= df['host_country'].replace({'nan':np.nan,'brasil':'brazil','great britain': 'united kingdom', 'russian fed.': 'russia'})\n",
    "#create the home country column\n",
    "df['home_country']= df['nation'].map(count_dict)\n",
    "df['home_country'].head()\n",
    "\n",
    "#create the expat columns\n",
    "df.loc[df['home_country']!=df['host_country'], 'expat'] = 1\n",
    "df.loc[df['home_country']==df['host_country'], 'expat'] = 0\n",
    "#change some mismatch between home-host country that's caused by nan into nans \n",
    "df['expat'] =np.where(((df['host_country'].isnull()) | (df['home_country'].isnull())), np.nan, df['expat'] )\n",
    "\n",
    "#create team size\n",
    "#team size of people, based on shared manager, so managers are only counted in the team of their manager\n",
    "df['team_size']= df.groupby('manager_id')['id'].transform('nunique') #this wont be accurate because of filling the missing values\n",
    "\n",
    "df['is_norsk']= np.where(df['nation']=='norwegian', 1, 0)\n",
    "df['in_norge']= np.where(df['host_country']=='norway', 1, 0)\n",
    "\n",
    "df['attend_avg']=df.groupby(['id'])['attend'].transform('mean').round()\n",
    "df['absence_avg']=df.groupby(['id'])['absence'].transform('mean').round()\n",
    "\n",
    "#see the minimum row number someone has\n",
    "df.groupby('id')['id'].count().unique()\n",
    "miss=df[df.isnull().any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single row per person\n",
    "So far we had 13 rows per person, one row per month. But running analysis with that data is like using duplicates of your data with small adjustments. So I kept the data only for the last month for each person. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I did that, I created a new column per column to add the info about each person's manager. So for each employee manager age, manager gender, manager certificate etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of managers\n",
    "manager_ids=list(df['manager_id'].unique())\n",
    "#dataframe for the managers\n",
    "managers=df[df['id'].isin(manager_ids)]\n",
    "\n",
    "#use the managers dataset to get info about each persons manager\n",
    "df_man = pd.merge(df, managers.set_index(['date','id']), left_on=['date', 'manager_id'], how='left', right_index=True, suffixes=('', '_man'))\n",
    "\n",
    "df_man.dropna(inplace=True)\n",
    "\n",
    "#narrow the dataset to have single line per person\n",
    "idx = df_man.groupby('id')['date'].transform(max) == df_man['date'] #choose the last date for each person\n",
    "df_narrow = df_man[idx]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_narrow.to_csv('data/processed/single_df_filled.csv', encoding='utf-8', index=False)\n",
    "df_man.to_csv('data/processed/full_df_filled.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
