{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The RFC Model\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "default_path=#path\n",
    "os.chdir(default_path)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import average_precision_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "df= pd.read_csv(\"data/processed/full_df_filled_coded.csv\")\n",
    "from 1_data_preprocessing import test_train_manual\n",
    "from 1_data_preprocessing import select_features\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create train test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_train, y_test, y_train = test_train_manual(df, 'Leavers', 'id')\n",
    "#select_features runs a RFC model with all features and selects the most important features\n",
    "imp_X_train, imp_X_test, feature_importances = select_features(X_test, X_train, y_test, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with reduced features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the expanded model on only the important features\n",
    "rf = RandomForestClassifier(n_estimators= 400, random_state=42)\n",
    "rf.fit(imp_X_train, y_train);\n",
    "\n",
    "print(classification_report(y_test, rf.predict(imp_X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with down sampling\n",
    "We have a very unbalanced data set. So we'll try downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the percentage of leavers\n",
    "count_stay = len(df[df[\"Leavers\"]==0]) \n",
    "count_leav = len(df[df[\"Leavers\"]==1]) \n",
    "perc_stay = count_stay/(count_stay+count_leav)\n",
    "print(\"percentage of stay is\",perc_stay*100)\n",
    "perc_leav= count_leav/(count_stay+count_leav)\n",
    "print(\"percentage of leave \",perc_leav*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll only downsample the training set. To do that, we first combine the y_train with the X training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the training X and y \n",
    "imp_X_train[\"Leavers\"]= y_train\n",
    "df_train = imp_X_train.copy().reset_index(drop=True) # for naming \n",
    "imp_X_train.drop(columns='Leavers', inplace=True)\n",
    "print(\"length of training df\",len(df_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need a portion of non leavers and will take whole df of Leavers. We'll try a range of portions, and choose the best performing one. For example portion of 4 means there are 4 non-leavers for each leaver. So we choose portion x number of leavers data points among the stay indices (stay_ind)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#array of indices for leavers and non-leavers\n",
    "leav_ind= np.array(df_train[df_train.Leavers==1].index)\n",
    "stay_ind = np.array(df_train[df_train.Leavers==0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample(stay_ind,leav_ind,times):#times denote the normal df = times*fraud df\n",
    "    #choose a number of indices from stay based on portion\n",
    "    stay_ind_undersample = np.array(np.random.choice(stay_ind,(times*count_leav),replace=False)) \n",
    "    undersample_df= np.concatenate([leav_ind,stay_ind_undersample]) #indices for all leavers and some stayers\n",
    "    undersample_df = df_train.iloc[undersample_df,:] #create the df based on indices\n",
    "    \n",
    "    print(\"the stay proportion is :\",len(undersample_df[undersample_df.Leavers==0])/len(undersample_df['Leavers']))\n",
    "    print(\"the leav proportion is :\",len(undersample_df[undersample_df.Leavers==1])/len(undersample_df['Leavers']))\n",
    "    print(\"total number of record in resampled df is:\",len(undersample_df['Leavers']))\n",
    "    #seperate the X and y again\n",
    "    features=undersample_df.columns.values.tolist()\n",
    "    y=['Leavers']\n",
    "    X=[i for i in features if i not in y]\n",
    "    \n",
    "    under_X_train=undersample_df[X]\n",
    "    under_y_train=undersample_df['Leavers']\n",
    "    return(under_X_train, under_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train this model using undersample data and test for the whole data test set. We do this for different proportions in the range of 4-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4,8):\n",
    "    print(\"the undersample data for {} proportion\".format(i))\n",
    "    print()\n",
    "    (under_X_train, under_y_train)=undersample(stay_ind,leav_ind,i)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    print()\n",
    "    print(\"the model classification for {} proportion\".format(i))\n",
    "    print()\n",
    "    \n",
    "    clf=RandomForestClassifier(n_estimators=100)\n",
    "    clf.fit(under_X_train, under_y_train)\n",
    "    print(classification_report(y_test, clf.predict(imp_X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best performnace is with the 6 proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(under_X_train, under_y_train)=undersample(stay_ind,leav_ind,6)\n",
    "\n",
    "rf.fit(under_X_train, under_y_train)\n",
    "print(classification_report(y_test, rf.predict(imp_X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIND THE BEST PARAMETERS\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "from pprint import pprint\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf.get_params())\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 3)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 120, num = 3)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRY WITH THE BETTER PARAMETERS IF YOU DID THE PARAMETER SEARCH\n",
    "rf_imp_para = RandomForestClassifier(n_estimators= 400, \n",
    "                                random_state=42, \n",
    "                                min_samples_leaf=1, \n",
    "                                max_features='sqrt',\n",
    "                                bootstrap= True\n",
    "                                )\n",
    "rf_imp_para.fit(under_X_train, under_y_train)\n",
    "predictions=rf_imp_para.predict(imp_X_test)\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test Accuracy\n",
    "print(\"Train Accuracy :: \", accuracy_score(y_train, rf_imp_para.predict(imp_X_train)))\n",
    "print(\"Test Accuracy  :: \", accuracy_score(y_test, predictions))\n",
    "cm = metrics.confusion_matrix(y_test, predictions)\n",
    "print(cm)\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Accuracy Score: {0}'.format(accuracy_score(y_test, predictions))\n",
    "plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
    "modelCV = rf_imp_para\n",
    "scoring = 'accuracy'\n",
    "results = model_selection.cross_val_score(modelCV, under_X_train, under_y_train, cv=kfold, scoring=scoring)\n",
    "print(\"10-fold cross validation average accuracy: %.3f\" % (results.mean()))\n",
    "print(results.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRECISION RECALL CURVE\n",
    "\n",
    "# precision-recall curve and f1\n",
    "#from sklearn.datasets import make_classification\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "rf_imp=rf\n",
    "# predict probabilities\n",
    "probs = rf_imp.predict_proba(imp_X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# predict class values\n",
    "yhat = rf_imp.predict(imp_X_test)\n",
    "# calculate precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, probs)\n",
    "# calculate F1 score\n",
    "f1 = f1_score(y_test, yhat)\n",
    "# calculate precision-recall AUC\n",
    "auc = auc(recall, precision)\n",
    "# calculate average precision score\n",
    "ap = average_precision_score(y_test, probs)\n",
    "print('f1=%.3f auc=%.3f ap=%.3f' % (f1, auc, ap))\n",
    "# plot no skill\n",
    "plt.plot([0, 1], [0.5, 0.5], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(recall, precision, marker='.')\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export the model\n",
    "I wanted to export one of the trees, cause it gives a more tangible material for presenting the results, even though it's not very imformative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#________________EXPORTING THE MODEL\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "\n",
    "estimator=rf_imp_para.estimators_[10]\n",
    "# Export as dot file\n",
    "export_graphviz(estimator, out_file='tree.dot', \n",
    "                feature_names = under_X_train.columns,\n",
    "                class_names = True,\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "# Convert to png using system command (requires Graphviz)\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Appl/release/bin'\n",
    "(graph,) = pydot.graph_from_dot_file('tree.dot')\n",
    "graph.write_png('tree_5.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
